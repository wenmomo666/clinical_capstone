{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/PubMed-w2v.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1118\u001b[0m             \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode should be a string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shortcut_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/PubMed-w2v.bin'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('Data/PubMed-w2v.bin', \n",
    "                                                         binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351706\n"
     ]
    }
   ],
   "source": [
    "vocab = model.vocab.keys()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Required Files & Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nct_ids_by_year = pickle.load(open(\"Data/ids_by_year_fda_reg_with_pos.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = pd.read_csv('Data/Studies.csv',\n",
    "                      index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13646, 64)\n"
     ]
    }
   ],
   "source": [
    "studies_sel = studies[studies['is_fda_regulated_drug']==True].copy()\n",
    "print(studies_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies_sel['study_first_submitted_date'] = pd.to_datetime(studies_sel['study_first_submitted_date'],\n",
    "                                                           format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11484, 64)\n"
     ]
    }
   ],
   "source": [
    "studies_sel = studies_sel[studies_sel['study_first_submitted_date'].dt.year.isin(range(2014,2019))]\n",
    "print(studies_sel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Similarity Matrix Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = stopwords.words('english')\n",
    "stop_list.extend((\"a\", \"an\",\"the\",\"with\",\"ii\",\"iii\",\"iv\",\"non\",\n",
    "                  \"studies\",\"use\",\"study\",\"multiple\", \"single\", \"double\",\n",
    "                  \"this\",\"these\",\"those\",\"care\",\"effect\",\"health\",\"patients\",\n",
    "                  \"trial\",\"treatment\",\"versus\",\"clinical\",\"clinic\",\"controlled\",\"control\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_pipeline(series,stop_list):\n",
    "    series = series.apply(lambda x: x.strip().lower().split(' '))\n",
    "    series = series.apply(lambda x: [elem.strip(string.punctuation) for elem in x])\n",
    "    series = series.apply(lambda x: [elem.strip() for elem in x if (elem not in stop_list) and (elem!='')])\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vec_from_list(str_list,model):\n",
    "    vec_list=[]\n",
    "    elem_list = []\n",
    "    for elem in str_list:\n",
    "        try:\n",
    "            curr_vec = model[elem]\n",
    "            vec_list.append(curr_vec)\n",
    "            elem_list.append(elem)\n",
    "        except:\n",
    "            continue\n",
    "    return pd.DataFrame(data=vec_list,\n",
    "                        index=elem_list).apply(np.mean,\n",
    "                                               axis=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec based similarity from `official_title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11484,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_title_series = studies_sel['official_title'].copy()\n",
    "official_title_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_title_series.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_title_series = nlp_pipeline(series=official_title_series,\n",
    "                                     stop_list=stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 21s, sys: 950 ms, total: 4min 22s\n",
      "Wall time: 4min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "official_title_vec_series = official_title_series.apply(lambda x: gen_vec_from_list(str_list=x,\n",
    "                                                                                    model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11484,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#handling null vectors\n",
    "official_title_vec_series = official_title_vec_series.apply(lambda x: np.array(np.zeros(shape=(200,))) if len(x)==0 else x)\n",
    "official_title_vec_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 11484)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_title_vec_df = pd.DataFrame.from_items(zip(official_title_vec_series.index, \n",
    "                                                    official_title_vec_series.values))\n",
    "official_title_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_title_vec_df = official_title_vec_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ids = studies_sel['nct_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_title_series.index = chosen_ids\n",
    "official_title_vec_series.index = chosen_ids\n",
    "official_title_vec_df.index = chosen_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list_ordered_by_year = {year:[elem[0] for elem in sorted(nct_ids_by_year[year].items(),\n",
    "                                                            key=lambda kv:kv[1])] for year in range(2014,2019)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = list(range(2014,2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 814 ms, sys: 183 ms, total: 997 ms\n",
      "Wall time: 641 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2vec_off_tit_sim_mat_by_year = {}\n",
    "for year in year_list:\n",
    "    word2vec_off_tit_sim_mat_by_year[year] = pd.DataFrame(data=cosine_similarity(official_title_vec_df.loc[id_list_ordered_by_year[year]]),\n",
    "                                                          index=id_list_ordered_by_year[year],\n",
    "                                                          columns=id_list_ordered_by_year[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(709, 709), (963, 963), (1643, 1643), (4750, 4750), (3419, 3419)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word2vec_off_tit_sim_mat_by_year[year].shape for year in year_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(word2vec_off_tit_sim_mat_by_year,\n",
    "#             open('Output/sim_mat_off_t_word2vec.pkl',\"wb\"),\n",
    "#             protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec based similarity from `keywords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816715, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = pd.read_csv('/Users/harsheelsoin/Documents/Capstone_Project_Goldman_Sachs/Data/data_by_tables/Keywords.csv',\n",
    "                       index_col=0)\n",
    "keywords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29631, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_sel = keywords[keywords['nct_id'].isin(chosen_ids)].copy()\n",
    "keywords_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6275, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_sel = keywords_sel.groupby('nct_id').apply(lambda x: x['downcase_name'].tolist()).reset_index()\n",
    "keywords_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_sel.columns = ['nct_id','keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_sel['keywords'] = keywords_sel['keywords'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_sel.set_index('nct_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6275,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_sel = pd.Series(data=keywords_sel['keywords'].values,\n",
    "                         index=keywords_sel.index)\n",
    "keywords_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_sel = nlp_pipeline(series=keywords_sel,\n",
    "                            stop_list=stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 1.06 s, total: 2min 29s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "keywords_sel = keywords_sel.apply(lambda x: gen_vec_from_list(str_list=x,\n",
    "                                                              model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11484"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = []\n",
    "for year in year_list:\n",
    "    all_ids += id_list_ordered_by_year[year]\n",
    "\n",
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11484, 2)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_sel_all_ids = pd.concat(objs=[pd.Series(data=all_ids,\n",
    "                                                 index=all_ids),\n",
    "                                       keywords_sel],\n",
    "                                 axis=1)\n",
    "keywords_sel_all_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_sel_all_ids.drop(labels=[0],\n",
    "                          axis=1,\n",
    "                          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addressing null vectors\n",
    "keywords_sel_all_ids[1] = keywords_sel_all_ids[1].apply(lambda x: np.array(np.zeros(shape=(200,))) if ((isinstance(x,float)) or (len(x)==0)) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11484, 200)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_vec_df = pd.DataFrame.from_items(zip(keywords_sel_all_ids.index, \n",
    "                                                    keywords_sel_all_ids[1].values)).T\n",
    "keywords_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 812 ms, sys: 241 ms, total: 1.05 s\n",
      "Wall time: 874 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2vec_keywords_sim_mat_by_year = {}\n",
    "for year in year_list:\n",
    "    word2vec_keywords_sim_mat_by_year[year] = pd.DataFrame(data=cosine_similarity(keywords_vec_df.loc[id_list_ordered_by_year[year]]),\n",
    "                                                          index=id_list_ordered_by_year[year],\n",
    "                                                          columns=id_list_ordered_by_year[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(word2vec_keywords_sim_mat_by_year,\n",
    "#             open(\"Output/sim_mat_keyword_word2vec.pkl\",\"wb\"),\n",
    "#             protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec based similarity from `detailed descriptions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183881, 3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_descriptions = pd.read_csv('/Users/harsheelsoin/Documents/Capstone_Project_Goldman_Sachs/Data/data_by_tables/Detailed_Descriptions.csv',\n",
    "                                    index_col=0)\n",
    "detailed_descriptions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7230, 3)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_descriptions_sel = detailed_descriptions[detailed_descriptions['nct_id'].isin(chosen_ids)].copy()\n",
    "detailed_descriptions_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7230,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_descriptions_sel = pd.Series(data=detailed_descriptions_sel['description'].values,\n",
    "                                      index=detailed_descriptions_sel['nct_id'].tolist())\n",
    "detailed_descriptions_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7230,)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_descriptions_sel = nlp_pipeline(series=detailed_descriptions_sel,\n",
    "                                         stop_list=stop_list)\n",
    "detailed_descriptions_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 4.77 s, total: 4min 1s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "detailed_descriptions_sel = detailed_descriptions_sel.apply(lambda x: gen_vec_from_list(str_list=x,\n",
    "                                                                                        model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11484, 2)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_desc_sel_all_ids = pd.concat(objs=[pd.Series(data=all_ids,\n",
    "                                                     index=all_ids),\n",
    "                                       detailed_descriptions_sel],\n",
    "                                      axis=1)\n",
    "detailed_desc_sel_all_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_desc_sel_all_ids.drop(labels=[0],\n",
    "                              axis=1,\n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addressing null vectors\n",
    "detailed_desc_sel_all_ids[1] = detailed_desc_sel_all_ids[1].apply(lambda x: np.array(np.zeros(shape=(200,))) if ((isinstance(x,float)) or (len(x)==0)) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11484, 200)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_desc_vec_df = pd.DataFrame.from_items(zip(detailed_desc_sel_all_ids.index, \n",
    "                                              detailed_desc_sel_all_ids[1].values)).T\n",
    "detailed_desc_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 807 ms, sys: 243 ms, total: 1.05 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2vec_detailed_desc_sim_mat_by_year = {}\n",
    "for year in year_list:\n",
    "    word2vec_detailed_desc_sim_mat_by_year[year] = pd.DataFrame(data=cosine_similarity(detailed_desc_vec_df.loc[id_list_ordered_by_year[year]]),\n",
    "                                                          index=id_list_ordered_by_year[year],\n",
    "                                                          columns=id_list_ordered_by_year[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(word2vec_detailed_desc_sim_mat_by_year,\n",
    "#             open(\"Output/sim_mat_d_desc_word2vec.pkl\",\"wb\"),\n",
    "#             protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
